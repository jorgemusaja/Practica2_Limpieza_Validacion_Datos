---
title: "Práctica 2"
author: "Jorge Cutipa Musaja"
date: '`r format(Sys.Date(),"%e de %B, %Y")`'
output:
  #pdf_document:
    #toc: yes
  html_document:
    toc: yes
---

```{r, echo=FALSE, message=FALSE}
library(ggplot2)
library(dplyr)
library(tidyr)
library(VIM)
library(caret)
library(C50)
```

```{r, echo=FALSE}
datos <- read.csv("train.csv", stringsAsFactors=FALSE)
aplicar <- read.csv("test.csv", stringsAsFactors=FALSE)
```

#1. Descripción del dataset

En abril de 1912, durante su viaje inaugural, el Titanic se hundió después de chocar con un iceberg, matando a 1502 de 2224 pasajeros y tripulantes. Una de las razones por las que el naufragio llevó a tal pérdida de vidas humanas fue que no había suficientes botes salvavidas para los pasajeros y la tripulación. Aunque siempre habrá algún elemento de azar a considerar, algunos grupos de personas tenían más probabilidades de sobrevivir al hundimiento que otros.  

El objetivo de esta práctica es elaborar un árbol de clasificación, para predecir que grupos de pasajeros y tripulantes tienen - o mejor dicho, tenían - una mayor probabilidad de sobrevivir al hundimiento del Titanic.  

Una descripción de los tipos de datos disponibles es lo que visualizaremos a continuación:  

```{r}
glimpse(datos)
```

Como se observa, Survived y Pclass han sido consideradas como variables numéricas, cuando en realidad son de tipo *clase (factor)*. Corregiremos esto.

```{r}
datos$Survived <- factor(datos$Survived)
datos$Pclass <- factor(datos$Pclass)
```

En resumen, en total, se tienen `r dim(datos)[1]` registros y `r dim(datos)[2]` variables, incluyendo a la variable objetivo: Survived.  

#2. Integración y selección de los datos de interés a analizar 

Como realizaremos un árbol de clasificación, no es necesario hacer una preselección de variables relevantes. Lo único que haremos será eliminar variables que no aportan información, como el nombre de los pasajeros, número de ticket, entre otros.

```{r}
datos <- datos[,colnames(datos)!="PassengerId"]
datos <- datos[,colnames(datos)!="Name"]
datos <- datos[,colnames(datos)!="Ticket"]
datos <- datos[,colnames(datos)!="Cabin"]
```

Ahora, en total, se tienen `r dim(datos)[1]` registros y `r dim(datos)[2]` variables, incluyendo a la variable objetivo: Survived.  

#3. Limpieza de los datos

##3.1. ¿Los datos contienen ceros o elementos vacíos? ¿Cómo gestionarías cada uno de estos casos?

Podemos crear una función para identificar las variables cos elementos vacíos

```{r}
datos.na = data.frame(sapply(datos, complete.cases)) 
sapply(-datos.na+1, sum) #La suma de cada variable nos indicará cuántos valores perdidos tiene cada variable, si es que los tuviese

```

Como se observa, el número de valores perdidos para Age es relativamente alto. Una opción sería imputar los valores faltantes en Age con la ayuda de algún algoritmo como k-means; otra opción es eliminar todos los registros con valores perdidos en Age, pues aún eliminando estos registros, tendríamos suficiente muestra para construir nuestro árbol de clasificación.  

Optaremos por esta última alternativa, no sin antes verificar que los valores perdidos no siguen algún patrón. Para ello, utilizaremos una matrixplot de variables cuantitativas.  

```{r, warning=FALSE}
datos.num <- datos[sapply(datos, is.numeric)]
datos.num$Survived <- datos$Survived
matrixplot(datos.num, sortby = "Survived") 
```

Como podemos observar, ordenando los datos respecto a nuestra variable objetivo, los valores perdidos en Age (representados en color rojo) no siguen ningún patrón. Por tanto, procederemos a eliminar los registros con valores perdidos en Age.     

```{r}
datos <- filter(datos, is.na(datos$Age)==F)
```

Ahora, en total, se tienen `r dim(datos)[1]` registros y `r dim(datos)[2]` variables, incluyendo a la variable objetivo: Survived.  

Además, debemos verificar que, para el caso de las variables categóricas, todos sus valores están correctamente etiquetados.

```{r}
apply(datos, 2, table)
```

Como se observa, para el caso de Embarked, dos de sus valores no están etiquetados. Elimaremos los dos registros correspondientes.  

```{r}
datos <- filter(datos, datos$Embarked=="C" | datos$Embarked=="Q" | datos$Embarked=="S")
```
Por tanto, en total, se tienen `r dim(datos)[1]` registros y `r dim(datos)[2]` variables, incluyendo a la variable objetivo: Survived.  


##3.2. Identificación y tratamiento de valores extremos.

Para identificar valores extremos realizaremos boxplot de cada variable numérica en el dataset.

```{r}
datos.num <- datos[sapply(datos, is.numeric)]

for (i in 1:dim(datos.num)[2]){
  boxplot(datos.num[,i], main=names(datos.num)[i], border = "blue", col = "grey90")
  }
```

Gráficamente, podemos interpretar que para Age y Fare se observa una gran cantidad de valores extremos; sin embargo, será mejor inspeccionar al detalle cuántos valores extremos tenemos en estas dos variables.  

```{r}
#Valores extremos para Age
boxplot.stats(datos$Age)$out

#Valores extremos para Fare
boxplot.stats(datos$Fare)$out
```

Podemos observar que en el caso de Fare es donde se tiene un elevado número de valores extremos. Una solución podría ser recortar nuevamente la muestra, en los registros correspondientes a los valores extremos de Fare; sin embargo, debemos recordar que el problema de los valores extremos se extiende cuando debemos hacer contrastes de hipótesis, correlaciones, regresiones, etc. En nuestro caso, un árbol de clasificación es un método computacional, y si bien es cierto que se rige bajo ciertas normas estadísticas, que no existan valores extremos en las variables no es un requisito para su elaboración. Por tanto, mantendremos el dataset sin ningún cambio.

#4. Análisis de los datos  

##4.1. Selección de los grupos de datos que se quieren analizar/comparar

Seleccionamos los conjuntos de entrenamiento (train) y prueba (test):  

```{r}
set.seed(64)
ids <- createDataPartition(datos$Survived,
                           p = 0.7,
                           list = F)

train <- datos[ids,]
test <- datos[-ids,]
```

Por tanto, del dataset original de `r dim(datos)[1]` registros, se han tomado `r dim(train)[1]` registros para el dataset train y `r dim(test)[1]` registros para el dataset test.  

##4.2. Comprobación de la normalidad y homogeneidad de la varianza  

No aplica esta comprobación para el caso del árbol de clasificación. Lo importante es tener un dataset balanceado en el target respecto al dataset original, que ya se ha logrado en el apartado anterior. Y se puede corroborar con la siguientes tablas:  

```{r}
prop.table(table(datos$Survived))
prop.table(table(train$Survived))
```

##4.3. Aplicación de pruebas estadísticas para comparar los grupos de datos

Elaboraremos el árbol de clasificación  

```{r}
tree <- C5.0(Survived ~ ., data=train)
```

Mostramos los resultados del entrenamiento

```{r}
summary(tree)
```

Aplicamos el árbol de clasificación al test

```{r}
newdata <- test[,colnames(test)!="Survived"]
prediccion <- predict(tree, newdata=newdata, type="class")
```

Mostramos los resultados de aplicar el árbol de clasificación al test

```{r}
confusionMatrix(data=prediccion, reference=test$Survived, positive="1")
```

A fin de mejorar la predicción, podemos incorporar un bosque, sin embargo, a fin de elegir el mejor número de árboles para nuestro bosque, incorporaremos un método de validación cruzada para elegir el número de árboles más adecuado.

```{r, warning=FALSE}
ctrl <- trainControl(method = "cv", number = 5)

grid <- expand.grid(model = "tree",
                    trials = seq(1,100,5),
                    winnow = c(FALSE, TRUE))

set.seed(64)
modelos <- train(Survived ~ ., data = train,
                 method = "C5.0",
                 trControl = ctrl,
                 tuneGrid = grid)

modelos$bestTune
```

Podemos representar gráficamente los resultados  

```{r}
ggplot(data = modelos$results, aes(x = trials, y = Accuracy, color = winnow)) +
  geom_line() + 
  geom_point() +
  theme_gray() +
  theme(legend.position = "bottom")
```

Aplicaremos entonces un bosque con 46 árboles.   

```{r}
bosque <- C5.0(Survived ~ ., data=train, trials=46)
```

Mostramos los resultados del entrenamiento

```{r}
summary(bosque)
```

Aplicamos el bosque de decisión al test

```{r}
newdata <- test[,colnames(test)!="Survived"]
prediccion <- predict(bosque, newdata=newdata, type="class")
```

Mostramos los resultados de aplicar el bosque de decisión al test

```{r}
confusionMatrix(data=prediccion, reference=test$Survived, positive="1")
```

Como se observa, hemos ganado algunos puntos en el poder de predicción.

#5. Representación de los resultados a partir de tablas y gráficas.

De https://www.kaggle.com/c/titanic se descargaron dos dataset. El primero es el que hemos venido utilizando para hacer el train y test. El segundo dataset es el siguiente:

```{r}
glimpse(aplicar)
```

Como puede observarse, no contiene a la variable Survived. Es decir, que una vez que utilicemos el bosque modelado no podremos elaborar una matriz de confusión ni tampoco evaluar el Accuracy; sin embargo, la predicción que obtangamos nos servirá para participar en la competencia de Kaggle.

```{r}
aplicar$Pclass <- factor(aplicar$Pclass)
prediccion <- predict(bosque, newdata=aplicar, type="class")
write.csv(prediccion, "prediccion.csv")
```

#6. Resolución del problema. 

A manera de conclusión, podemos afirmar que hemos contruido un bosque cuyo poder de acierto en la predicción es de alrededor del 76%.

